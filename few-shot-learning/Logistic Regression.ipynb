{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Classification using Logistic Regression\n",
    "\n",
    "In this notebook, we have implemented baseline models Logistic Regression Model. Later, we have also taken the layer embeddings to analyse the decision boundaries using clustering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.7/site-packages (4.5.1.48)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.18.4)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score, log_loss\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, f1_score\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 6\n",
    "ncols = 4\n",
    "pic_index = 0\n",
    "\n",
    "BASE_DATA_FOLDER = \"./data\"\n",
    "TRAIN_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_folder_name in os.listdir(TRAIN_DATA_FOLDER):\n",
    "    class_folder_path = os.path.join(TRAIN_DATA_FOLDER, class_folder_name)\n",
    "    for image_path in glob(os.path.join(class_folder_path, \"*.jpeg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "        images.append(image)\n",
    "        labels.append(class_folder_name)\n",
    "    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        image = np.stack((image,)*3, axis=-1)    \n",
    "        images.append(image)\n",
    "        labels.append(class_folder_name)\n",
    "    for image_path in glob(os.path.join(class_folder_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "        images.append(image)\n",
    "        labels.append(class_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "pre = preprocessing.LabelEncoder()\n",
    "pre.fit(labels)\n",
    "labels_numeric = pre.transform(labels)\n",
    "Num_Class = 3\n",
    "\n",
    "def OneHotEncoded(y_train):\n",
    "    y_t=np.zeros((len(y_train),Num_Class), dtype=int)\n",
    "    for i,x in enumerate(y_train):\n",
    "        y_t[i][int(x)-1]=1\n",
    "    return y_t\n",
    "\n",
    "labels = OneHotEncoded(labels_numeric)\n",
    "\n",
    "X_train, X_test= train_test_split(images, test_size=0.2, random_state=42)\n",
    "y_train, y_test= train_test_split(labels, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape(200, 224, 224, 3)\n",
    "X_test = X_test.reshape(51, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXvpRUAy6Lt1"
   },
   "source": [
    "## the next step is to define the model that will be trained to recognize covid, normal or Viral Pneumonia from these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vgg_bf = X_train.reshape(X_train.shape[0],-1)\n",
    "valid_vgg_bf = X_test.reshape(X_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation VGG LogLoss 1.1669545136449881\n",
      "Validation VGG Accuracy 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "compare_loss={}\n",
    "compare_accuracy = {}\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=147)\n",
    "logreg.fit(train_vgg_bf, (y_train * range(Num_Class)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "valid_preds = logreg.predict(valid_vgg_bf)\n",
    "compare_loss['Vgg16']=log_loss(y_test, valid_probs)\n",
    "compare_accuracy['Vgg16']=accuracy_score((y_test * range(Num_Class)).sum(axis=1), valid_preds)\n",
    "print('Validation VGG LogLoss {}'.format(compare_loss['Vgg16']))\n",
    "print('Validation VGG Accuracy {}'.format(compare_accuracy['Vgg16']))\n",
    "y_lr_test = (y_test * range(Num_Class)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8823529411764706\n",
      "F1 score: 0.8833402260821615\n",
      "Recall: 0.8838665290677675\n",
      "Precision: 0.8911764705882352\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        15\n",
      "           1       1.00      0.82      0.90        17\n",
      "           2       0.85      0.89      0.87        19\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.89      0.88      0.88        51\n",
      "weighted avg       0.89      0.88      0.88        51\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[14  0  1]\n",
      " [ 1 14  2]\n",
      " [ 2  0 17]]\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy:', accuracy_score(y_lr_test, valid_preds))\n",
    "print ('F1 score:', f1_score(y_lr_test, valid_preds, average='macro'))\n",
    "print ('Recall:', recall_score(y_lr_test, valid_preds, average='macro'))\n",
    "print ('Precision:', precision_score(y_lr_test, valid_preds, average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_lr_test,valid_preds))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_lr_test, valid_preds))\n",
    "\n",
    "X = train_vgg_bf\n",
    "numpy_labels = y_train\n",
    "numpy_all = logreg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sillouette Score using K-Means 0.1567434865534098\n"
     ]
    }
   ],
   "source": [
    "clusterer = KMeans(n_clusters=3)\n",
    "preds = clusterer.fit_predict(X)\n",
    "centers = clusterer.cluster_centers_\n",
    "score = silhouette_score(X, preds)\n",
    "print (\"Sillouette Score using K-Means\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
